services:
  admin:
    image: ${DOCKER_IMAGE:-video-processor:latest}
    restart: unless-stopped
    volumes:
      - .:/code
      - ${STORAGE_MOUNT:-.}:/output
      - ${BULK_VIDEO_DIR:-/dev/null}:/bulk-videos:ro
    env_file:
      - .env
    environment:
      STORAGE_MOUNT: /output
    command: ['python3', 'manage.py', 'runserver', '0.0.0.0:8000']
    ports:
      - "8000:8000"

  chunk_video:
    image: ${DOCKER_IMAGE:-video-processor:latest}
    restart: unless-stopped
    volumes:
      - .:/code
      - ${STORAGE_MOUNT:-.}:/output
    env_file:
      - .env
    environment:
      STORAGE_MOUNT: /output
    command: ['celery', '-A', 'video_processor', 'worker', '-n', 'chunk@%h', '-l', 'INFO', '-Q', 'chunk_video', '--concurrency', '1']
    deploy:
      replicas: 1
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  extract:
    image: ${DOCKER_IMAGE:-video-processor:latest}
    restart: unless-stopped
    volumes:
      - .:/code
      - ${STORAGE_MOUNT:-.}:/output
    env_file:
      - .env
    environment:
      STORAGE_MOUNT: /output
    command: ['celery', '-A', 'video_processor', 'worker', '-n', 'extract@%h', '-l', 'INFO', '-Q', 'extract', '--concurrency', '1', '--pool', 'solo']
    deploy:
      replicas: ${EXTRACT_WORKERS_PER_HOST}
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  detect:
    image: ${DOCKER_IMAGE:-video-processor:latest}
    restart: unless-stopped
    volumes:
      - .:/code
      - ${STORAGE_MOUNT:-.}:/output
    env_file:
      - .env
    environment:
      STORAGE_MOUNT: /output
    command: ['celery', '-A', 'video_processor', 'worker', '-n', 'detect@%h', '-l', 'ERROR', '-Q', 'detect', '--concurrency', '1', '--pool', 'solo']
    deploy:
      replicas: ${DETECT_WORKERS_PER_HOST}
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  create_output:
    image: ${DOCKER_IMAGE:-video-processor:latest}
    restart: unless-stopped
    volumes:
      - .:/code
      - ${STORAGE_MOUNT:-.}:/output
    env_file:
      - .env
    environment:
      STORAGE_MOUNT: /output
    command: ['celery', '-A', 'video_processor', 'worker', '-n', 'output@%h', '-B', '-l', 'INFO', '-Q', 'create_output', '--concurrency', '1']
    deploy:
      replicas: 1
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
  
#   If you just want to process things on a single machine, you can use these
#   containers for your DB and Celery Broker, respectively. Just make sure you
#   change your .env file to match.  
    
  db:
    image: 'postgres:15'
    restart: unless-stopped
    env_file:
      - .env
    environment:
      POSTGRES_PASSWORD: ${DB_PASS:-processor-password}
      POSTGRES_USER: ${DB_USER:-processor}
      POSTGRES_DB: ${DB_NAME:-processor}
    volumes:
      - postgresql:/var/lib/postgresql
      - postgresql_data:/var/lib/postgresql/data
    ports:
      - "${DB_PORT:-5432}:${DB_PORT:-5432}"

  redis:
    image: 'redis:latest'
    restart: unless-stopped
    ports:
      - '6379:6379'

volumes:
  postgresql:
  postgresql_data:
